%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
% Дополнительные комманды для данной работы:

\newcommand{\rb}[1]{ \left(#1\right) }


%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
%-------------------------------------------------------------------------------
\insertTitle{Планирование и анализ эксперимента}{4}{ПМ-63}{Кожекин М.В.}{Майер В.А.}{Назарова Т.А.}{Утюганов Д.С.}{9(1)}{2020}


%-------------------------------------------------------------------------------
\section{Цель работы}
Изучить методы оптимального планирования эксперимента при нелинейной параметризации функции отклика.


%-------------------------------------------------------------------------------
\section{Задание}

1. Изучить понятия локально-оптимального планирования и информационной
матрицы при нелинейной параметризации функции отклика, ознакомиться с видом
производственной функции Кобба-Дугласа.

2. По заданному типу технологии сформировать имитационную модель в виде
производственной функции Кобба-Дугласа. При этом задать истинные значения
для параметров, нелинейно входящих в модель. Выход модели зашумить, уровень
шума установить в пределах 15...20 \% от мощности полезного сигнала.

3. Выбрать план для затравочног оэксперимента, состоящий из небольшого числа
наблюдений, и смоделировать на его основе экспериментальные данные.

4. Оценить параметры модели по полученным экспериментальным данным. Для
этого необходимо перейти к линейной модели, воспользовавшись логарифмическим
представлением уравнения модели наблюдения. Параметры преобразованной модели
тогда можно оценить обычным «линейным» МНК.

5. Построить локально-оптимальный план эксперимента для исходной нелинейной
модели, воспользовавшись разработанной ранее программой синтеза дискретных
оптимальных планов и полученными оценками параметров модели. Число наблюдений
должно в 4...5 раз превышать число параметров модели.

6. По сформированной ранее (п. 2) имитационной модели провести имитационный
эксперимент в точках полученного локально-оптимального плана. Провести оценку
параметров и вычислить норму отклонения оценок от их истинны хзначений.
Вычислительный эксперимент повторить не менее 100  раз, каждый раз с новой
реализацией помехи. Вычислить среднее значение нормы отклонения оценок.
Процедуру повторить, используя в качестве плана эксперимента случайно расположенные
точки в факторном пространстве. В серии вычислительных экспериментов случайный
план фиксируется (выбирается один раз). Сделайте вывод об эффективности оптимального
планирования эксперимента для идентификации заданной нелинейной модели.

7. Оформить отчет, включающий в себя постановку задачи, оценки параметров
по затравочному эксперименту, полученный локально-оптимальный план, результаты
проведенного в п. 6  исследования и текст программы.

8. Защитить лабораторную работу. 
\vspace{20mm}



%-------------------------------------------------------------------------------
\section{Анализ}

Технология Кобба-Дугласа. Ресурсов два, изменяются в пределах [1, 10].
Постоянная отдача от масштаба. Локально-D-оптимальное планирование.
\vspace{5mm}

Модель наблюдения за объектом представляет собой уравнение вида:
\[y = \eta \rb{x, \Theta} + e, \quad \text{ где: } \]

y - значение отклика;

$\eta$ - нелинейная функция  вектора параметров $\Theta$;

$\Theta$ - вектор неизвестных параметров;

e - ошибка наблюдения
\vspace{5mm}


Функция Кобба-Дугласа $\eta \rb{x, \Theta}$ имеет вид:
\[y = \Theta_0 \cdot X_1^{\Theta_1} \cdot X_2^{\Theta_2}\]

Её логарифмическое представление:
\[y = \log(\Theta_0) + \Theta_1 \cdot \log(X_1) + \Theta_2 \cdot \log(X_2)\]

При постоянной отдаче от масштаба параметры удовлетворяют ограничению
\[\sum_{i=1}^k \Theta_i = 1\]
\vspace{5mm}


\textbf{Информационная матрица Фишера} для нелинейной модели зависит от $\hat{\Theta}$.
Приближенное значение нормированной информационной матрицы дискретного плана можно
вычислить по формуле
\[M \rb{\varepsilon_N, \hat{\Theta}} \approx M \rb{\varepsilon_N, \Theta_{true}} = 
\sum_{j=1}^n{p_j f\rb{x_j, \Theta_{true}} f^T\rb{x_j, \Theta_{true}}}, \quad \text{где}\]
\[f \rb{x, \hat{\Theta}} = \left.\frac{\partial \eta \rb{x, \Theta}}{\partial \Theta} \right|_{\Theta = \hat{\Theta}} = 
\rb{X_1^{\Theta_1} \cdot X_2^{\Theta_2},
\Theta_0 \cdot \Theta_1 \cdot X_1^{\Theta_1 - 1} \cdot X_2^{\Theta_2}, 
\Theta_0 \cdot X_1^{\Theta_1} \cdot \Theta_2 \cdot X_2^{\Theta_2 - 1}}^T\]

\textbf{Дисперсионная матрица} определяется как обратная к информационной, т.е.
\[D \rb{\varepsilon_N, \hat{\Theta}} = M^{-1} \rb{\varepsilon_N, \hat{\Theta}}\]
\pagebreak


Пусть $\Theta_{true}$ = [0.2, 0.4, 0.4], шум $\rho$ = 20\%, N = 3x5 = 15 точек, $\varepsilon$ = 1e-4.
\vspace{10mm}



\begin{tabular}{ll}
	% \toprule
	\textbf{Оптимальный план} & \textbf{Случайный план} \\
	\midrule
	\includegraphics[width=0.48\textwidth]{../pics/opt_plan.png} &  \includegraphics[width=0.48\textwidth]{../pics/rand_plan.png} \\
	RSS:  50.6925 &  RSS:  50.7152 \\
	отклонение нормы оценок:  0.0026 &  отклонение нормы оценок:  0.0027 \\
	% \bottomrule
\end{tabular}
\vspace{10mm}



\textbf{Вывод:}

Построение оптимального дискретного плана повышает точность оценки параметров
и, соответственно, точность модели. 

%-------------------------------------------------------------------------------
\section{Исходный код программы}
\myCodeInput{python}{PlanOfExp4.py}{../PlanOfExp4.py}

